## SPRINT 02

* ### *SQL Para Análise de Dados:*

O curso de SQL Para Análise de Dados abordou os fundamentos e técnicas essenciais para a manipulação e análise de dados utilizando a linguagem SQL. Foram apresentados comandos básicos, como SELECT, FROM, WHERE e DISTINCT, que permitem extrair informações específicas de um banco de dados. Além disso, foram explorados os operadores, que são utilizados para realizar comparações, combinações lógicas e ordenações nos dados. As funções agregadas foram introduzidas como uma maneira de calcular valores incluindo funções como SUM, COUNT, AVG, MIN e MAX. Os joins foram abordados como uma forma de combinar dados de várias tabelas, permitindo a análise conjunta de informações.

A utilização de unions foi explicada como uma forma de combinar resultados de consultas distintas em um único conjunto de resultados. As subqueries foram discutidas como consultas aninhadas que podem ser usadas para obter informações mais detalhadas e refinadas. O curso também abordou o tratamento de dados, incluindo a utilização de cláusulas como ORDER BY, GROUP BY e HAVING para classificar, agrupar e filtrar os resultados. A manipulação de tabelas foi explorada, permitindo a criação, atualização e exclusão de registros e estruturas de tabelas.


<br/>

* ### *Fundamentos de Big Data 3.0:*

No curso de Big Data, foram abordados conceitos essenciais para lidar com grandes volumes de dados complexos. Big Data envolve a análise de conjuntos de dados extremamente grandes, variados e complexos, provenientes de diversas fontes. Foram explorados sistemas de armazenamento, como Data Lakes, que armazenam dados brutos sem estruturação prévia; Data Stores, projetados para acesso rápido a dados estruturados; e Data Warehouses, utilizados para análise de dados históricos. Além disso, foram apresentados sistemas híbridos de armazenamento que combinam características de data lakes e data warehouses.

O armazenamento paralelo foi discutido, enfatizando a capacidade de processar e armazenar dados de forma distribuída em um cluster de computadores. Esse método permite dividir a carga de trabalho entre os nós do cluster, resultando em maior velocidade, escalabilidade e tolerância a falhas. O Hadoop Distributed File System (HDFS) foi mencionado como um exemplo popular de tecnologia de armazenamento paralelo.

A relação entre Big Data e Cloud Computing também foi explorada, destacando que a computação em nuvem fornece recursos como armazenamento, processamento e análise de dados por meio da internet, eliminando a necessidade de infraestrutura local.

Foram apresentados os conceitos de MLOps (Machine Learning Operations) e DataOps. MLOps refere-se à gestão do ciclo de vida de modelos de machine learning, desde o desenvolvimento até a implantação e monitoramento contínuo em produção. DataOps é uma metodologia que combina práticas ágeis de desenvolvimento e operações de dados para melhorar a colaboração, qualidade e velocidade dos fluxos de dados.

Outro tópico abordado foi o conceito de Dados como Serviço (DaaS), onde os dados são disponibilizados como um serviço, permitindo acesso e uso por meio da internet. Provedores de serviços gerenciam a coleta, armazenamento, processamento e fornecimento dos dados aos usuários, oferecendo fácil acesso, escalabilidade e atualizações regulares.

Por fim, foram apresentadas arquiteturas modernas de Big Data, como o Data Lakehouse e o Data Mesh. O Data Lakehouse combina as vantagens de um Data Lake e de um Data Warehouse, permitindo o armazenamento de dados brutos e a aplicação de estruturas sob demanda para análise avançada. O Data Mesh propõe uma abordagem descentralizada, distribuindo a responsabilidade pelos dados entre equipes específicas para promover a colaboração e flexibilidade no uso dos dados.
___

### CERTIFICADOS

* [SQL Para Análise de Dados](certificados/certificado-sql-udemy-diane-castedo.jpg)
* [Fundamentos de Big Data 3.0](certificados/certificado-big-data-dsa-diane-castedo.jpg)
___

### ATIVIDADES

* [Atividades Práticas de SQL](atividades-praticas-sql)

